# GET请求
import requests
r = requests.get('https://www.baidu.com')
print(type(r))
print(r.status_code)
print(type(r.text))
print(r.text[:100])
print(r.cookies)


r = requests.get('https://www.httpbin.org/get')
print(r.text)
# r = requests.post('https://www.httpbin.ort/post')
# r = requests.put('https://www.httpbin.com/put')
# r = requests.delete('https://www.httpbin.com/delete')
# r = requests.patch('https://www.httpbin.com/patch')

# 使用param参数就可以直接传递
# import requests
data = {
    'name': 'germey',
    'age': '25'
}
r = requests.get('https://www.httpbin.org/get', params=data)
print(r.text)

# 使用json方法解析返回结果
# import requests
r = requests.get('https://www.httpbin.org/get')
print(type(r.text))
print(r.json())
print(type(r.json()))

# 抓取网页
# import requests
import re
r = requests.get('http://ssr1.scrape.center/')
pattern = re.compile('<h2.*?>(.*?)</h2>', re.S)
titles = re.findall(pattern, r.text)
print(titles)

# 抓取二进制数据
# import requests
r = requests.get('https://scrape.center/favicon.ico')
print(r.text)
print(r.content)

# 保存抓取的二进制数据
import requests
r = requests.get('http://scrape.center/favicon.ico')
with open('favicon.ico', 'wb') as f:
    f.write(r.content)

# 添加请求头
# import requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:99.0) Gecko/20100101 Firefox/99.0'
}
r = requests.get('https://ssr1.scrape.center/', headers=headers)
print(r.text)


# POST请求
# import requests
data = {'name': 'germey', 'age': '25'}
r = requests.post('https://www.httpbin.org/post', data=data)
print(r.text)


# 响应
# import requests
r = requests.get('https://ssr1.scrape.center/')
print(type(r.status_code), r.status_code)
print(type(r.headers), r.headers)
print(type(r.cookies), r.cookies)
print(type(r.url), r.url)
print(type(r.history), r.history)

# requests 内置状态码查询对象
# import requests
r = requests.get('https://ssr1.scrape.center/')
exit() if not r.status_code == requests.codes.ok else print('Requests Successfully')



# 高级用法-->>>文件上传
# import requests
# files = {'file': open('favicon.ico', 'rb')}
# r = requests.post('https://httpbin.org/post', files=files)
# print(r.text)

# 高级用法--->>>Cookie设置
# import requests
# r = requests.get('https://www.baidu.com')
# print(r.cookies)
# for key, value in r.cookies.items():
#     print(key + '=' + value)

# cookie 保持登入
# import requests
# headers = {
#     'Cookie': 'share_code=MzAyODU5Jl8mMjcuMTg3LjIyNC41Mg==; PHPSESSID=5qkmktpfccpcvq86flrp8a2d81; Hm_lvt_a8dc54ec51e87376541aaf2c1ad569cd=1651235339; Hm_lpvt_a8dc54ec51e87376541aaf2c1ad569cd=1651235339; wx_refersh_time=1; qq_refersh_time=1; user_id=451466; user_login_token=phmvOV4yvJV%2F%2Fa6kjbAy0g%3D%3D'
# }
# r = requests.get('https://www.macw.com/mac', headers=headers)
# print(r.text)

# 通过cookies参数来设置Cookie信息
# import requests
# cookies = 'share_code=MzAyODU5Jl8mMjcuMTg3LjIyNC41Mg==; PHPSESSID=5qkmktpfccpcvq86flrp8a2d81; Hm_lvt_a8dc54ec51e87376541aaf2c1ad569cd=1651235339; Hm_lpvt_a8dc54ec51e87376541aaf2c1ad569cd=1651235339; wx_refersh_time=1; qq_refersh_time=1; user_id=451466; user_login_token=phmvOV4yvJV%2F%2Fa6kjbAy0g%3D%3D'
# jar = requests.cookies.RequestsCookieJar()
# headers = {
#     'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:99.0) Gecko/20100101 Firefox/99.0'
# }
# for cookie in cookies.split(';'):
#     key, value = cookie.split('=', 1)
#     jar.set(key, value)
# r = requests.get('https://www.macw.com/mac/pm#/admin', cookies=jar, headers=headers)
# print(r.text)


# session维持
# import requests
#  用cookie截取cookies
# requests.get('https://www.httpbin.org/cookies/set/number/123456789')
# r = requests.get('https://www.httpbin.org/cookies')
# print(r.text)
# 用session截取cookie
# import requests
# s = requests.Session()
# s.get('https://www.httpbin.org/cookies/set/number/123456789')
# r = s.get('https://www.httpbin.org/cookies')
# print(r.text)


# SSL证书验证
# import requests
# 错误
# response = requests.get('https://ssr2.scrape.center/')
# print(response.status_code)
# 正确
response = requests.get('https://ssr2.scrape.center/', verify=False)
print(response.status_code)
# 通过指定证书来忽略警告
# import requests
import urllib3
urllib3.disable_warnings()
response = requests.get('https://ssr2.scrape.center/', verify=False)
print(response.status_code)
# 通过捕获警告到日志的方式忽略警告
import logging
# import requests
logging.captureWarnings(True)
response = requests.get('https://ssr2.scrape.center/', verify=False)
print(response.status_code)
# 指定本地证书用作客户端证书
# import requests
# response = requests.get('https://ssr2.scrape.center', cert=('/path/server.crt', '/path/server.key')) # 因使用mac系统路径不对
# print(response.status_code)


# 超时设置
# import requests
r = requests.get('https://www.httpbin.org/get', timeout=None)  # timeout=(5, 30)        永久等待：timeout=None（或者不加参数）
print(r.status_code)


# 身份认证
# import requests
from requests.auth import HTTPBasicAuth
r = requests.get('https://ssr3.scrape.center/', auth=HTTPBasicAuth('admin', 'admin'))
print(r.status_code)
# 简写
# import requests
r = requests.get('https://ssr3.scrape.center/', auth=('admin', 'admin'))
print(r.status_code)
# OAuth认证
# import requests
# from reuqests_oauthlib import OAuth1
# url = 'https://api.twitter.com/1.1/account/verify_credentials.json'
# auth = OAuth1('YOUR_APP_KEY', 'YOUR_APP_SECRET',
#               'USER_OAUTH_TOKEN', 'USER_OAUTH_TOKEN_SECRET')
# requests.get(url, auth)
# print(requests)


# 代理设置  proxies
# import requests
# proxies = {'http': 'http://10.10.10.10:1080',       # 代理无效，请搜索有效带代理替换
#            'https': 'http://10.10.10.10:1080'
#            }
# requests.get('https://www.httpbin.org/get', proxies=proxies)

# 若代理需要使用上文所述带身份认证
# import requests
# proxies = {
#     'http': 'http://user:password@10.10.10.10:1080/',
#     'https': 'http://user:password@10.10.10.10:1080'
# }
# requests.get('https://www.httpbin.org/get', proxies=proxies)


# Prepared Request
from requests import Request, Session
url = 'https://www.httpbin.org/post'
data = {'name': 'germey'}
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:99.0) Gecko/20100101 Firefox/99.0'
}
s = Session()
req = Request('POST', url, data=data, headers=headers)
prepped = s.prepare_request(req)
r = s.send(prepped)
print(r.text)
